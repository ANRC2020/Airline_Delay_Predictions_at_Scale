{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "77a1046d-deda-458b-8759-ce11d372b0be",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# General\n",
    "import re\n",
    "import ast\n",
    "import time\n",
    "\n",
    "# Data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Spark Pandas API\n",
    "import pyspark.pandas as ps\n",
    "\n",
    "# Viz\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Spark SQL API\n",
    "from pyspark.sql import Window, DataFrame\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Specific Spark SQL functions\n",
    "from pyspark.sql.functions import row_number, when, concat#, #sum, row_number, concat, to_timestamp\n",
    "from pyspark.sql.functions import isnan, when, count, col, split, trim, lit, avg, lpad\n",
    "from pyspark.sql.functions import expr, mean, stddev, randn, to_date, round, upper, trim, countDistinct\n",
    "\n",
    "# Spark ML Lib functions\n",
    "from pyspark.ml.functions import vector_to_array\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.linalg import Vectors\n",
    "\n",
    "# Feature pipeline\n",
    "from pyspark.ml import Pipeline, Transformer\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, MinMaxScaler, VectorAssembler, Imputer, SQLTransformer, StandardScaler\n",
    "\n",
    "# Regression model\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.sql.functions import lit, col, row_number, monotonically_increasing_id, rand\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "import random\n",
    "\n",
    "import optuna\n",
    "from optuna.pruners import MedianPruner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4c99347f-1faa-4727-88a9-68f91e95b759",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Mount blob storae and grant team access\n",
    "blob_container  = \"261project\"       # The name of your container created in https://portal.azure.com\n",
    "storage_account = \"261teamderm\"  # The name of your Storage account created in https://portal.azure.com\n",
    "secret_scope = \"261teamderm\"           # The name of the scope created in your local computer using the Databricks CLI\n",
    "secret_key = \"261key\"             # The name of the secret key created in your local computer using the Databricks CLI\n",
    "team_blob_url = f\"wasbs://{blob_container}@{storage_account}.blob.core.windows.net\"  #points to the root of your team storage bucket\n",
    "mids261_mount_path      = \"/mnt/mids-w261\" # the 261 course blob storage is mounted here.\n",
    "# SAS Token: Grant the team limited access to Azure Storage resources\n",
    "spark.conf.set(\n",
    "  f\"fs.azure.sas.{blob_container}.{storage_account}.blob.core.windows.net\",\n",
    "  dbutils.secrets.get(scope = secret_scope, key = secret_key)\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8cfdf126-a1ab-4f66-a7f2-bcdf24cde4ea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(dbutils.fs.ls(f\"{team_blob_url}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a3b90b5a-8545-4d51-a14d-27dea32fa7d6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#fpath = f'{team_blob_url}/data/1yr_preprocessed_no.parquet'#f'{team_blob_url}/data/1yr_folds.parquet'\n",
    "FPATH = f'{team_blob_url}/data/5yr_preprocessed.parquet'\n",
    "df = spark.read.parquet(FPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "76958d28-c521-4086-96cd-21df85e3cba3",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "filterBlob": "{\"filterGroups\":[],\"syncTimestamp\":1733601465712}",
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0e7260cc-0a81-4278-8e10-52cf0554a553",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = df.filter(\"pagerank is not null\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5a4b6ec9-be50-4c1a-ac7b-908d1c80ee2e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9af418ec-099d-4e3c-bc61-19e6a969ddff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = df.filter(df.DEP_DEL15.isNotNull())\n",
    "\n",
    "# Create a combined column for fold and split\n",
    "df = df.withColumn(\n",
    "    \"fold_split\",\n",
    "    concat(col(\"foldCol\"), lit(\"_\"), col(\"split\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7beabe4b-4709-4828-a839-24f229332e17",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class_counts = df.groupBy(\"DEP_DEL15\").count().collect()\n",
    "class_counts_dict = {row[\"DEP_DEL15\"]: row[\"count\"] for row in class_counts}\n",
    "print(class_counts_dict[0])\n",
    "print(class_counts_dict[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5b90692e-d438-4213-9681-62d60be79f09",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "balanced_df = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5d8516d2-be10-497b-ac06-178133c262d2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "balanced_df.groupBy(\"DEP_DEL15\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b1f959b3-9a24-4103-ae79-dcedcc779643",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "filterBlob": "{\"filterGroups\":[],\"syncTimestamp\":1733615493182}",
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(balanced_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "03f12c5c-0ecb-499a-8716-453ac217bc01",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "balanced_df.groupBy(\"foldCol\", \"split\").count().orderBy(\"foldCol\", \"split\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c6cb0d6c-81f9-42e8-a6ac-bcbe8bd9fb90",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Enumerate columns for ohe (\"categorical\"), already ohe (\"ohe\") and for scaling ()\n",
    "need_ohe_cols = ['QUARTER', 'MONTH', 'DAY_OF_WEEK','OP_UNIQUE_CARRIER', 'DEP_TIME_BLK', 'ARR_TIME_BLK', 'DAY_OF_MONTH']\n",
    "already_ohe_cols = ['ceiling_height_is_below_10000', 'ceiling_height_is_between_10000_20000', 'ceiling_height_is_above_20000']\n",
    "standard_scalar_cols = ['wind_direction', 'temperature', 'sea_level_pressure'] # wind, temp and pressure\n",
    "min_max_cols = ['CRS_ELAPSED_TIME', 'DISTANCE',\n",
    "                'visibility', 'dew_point', 'wind_speed', 'gust_speed' # vis, dew, weather and wind\n",
    "                ]\n",
    "\n",
    "# Consolidate\n",
    "label_col = 'DEP_DEL15'\n",
    "categorical_cols = need_ohe_cols + already_ohe_cols\n",
    "\n",
    "# Adding augmented features\n",
    "need_ohe_cols = need_ohe_cols + ['HIST_ARR_FLT_NUM', 'HIST_DEP_FLT_NUM'] # number of flights in the past\n",
    "already_ohe_cols = already_ohe_cols + ['isHoliday','specWeather']\n",
    "min_max_cols = min_max_cols + ['HIST_ARR_DELAY', 'HIST_DEP_DELAY', 'origin_yr_flights', 'dest_yr_flights']    \n",
    "numerical_cols = min_max_cols + standard_scalar_cols + ['pagerank'] # PageRank (which is null for yr1)\n",
    "\n",
    "# Removing extra time columns\n",
    "need_ohe_cols = [c for c in need_ohe_cols if c not in ['QUARTER', 'MONTH', 'DAY_OF_WEEK', 'DAY_OF_MONTH']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9efb4461-431c-4c68-873c-0bb83fd9d4fe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_train_filtered = balanced_df.dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0f1e05ae-26b3-416c-b2cb-5a95fc891a24",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "indexers = [StringIndexer(inputCol=col, outputCol=f\"{col}_index\", handleInvalid=\"keep\") for col in need_ohe_cols]\n",
    "encoders = [OneHotEncoder(inputCol=f\"{col}_index\", outputCol=f\"{col}_ohe\", dropLast=False) for col in need_ohe_cols]\n",
    "imputer = Imputer(strategy=\"mean\", inputCols=numerical_cols, outputCols=[f\"{col}_imputed\" for col in numerical_cols])\n",
    "\n",
    "minmax_assembler = VectorAssembler(inputCols=[f\"{col}_imputed\" for col in min_max_cols], outputCol=\"minmax_features\")\n",
    "minmax_scaler = MinMaxScaler(inputCol=\"minmax_features\", outputCol=\"scaled_minmax_features\")\n",
    "\n",
    "# Assemble input columns for StandardScaler\n",
    "standard_assembler = VectorAssembler(inputCols=[f\"{col}_imputed\" for col in standard_scalar_cols], outputCol=\"standard_features\")\n",
    "standard_scaler = StandardScaler(inputCol=\"standard_features\", outputCol=\"scaled_standard_features\", withMean=True, withStd=True)\n",
    "\n",
    "final_assembler = VectorAssembler(\n",
    "        inputCols=[f\"{col}_ohe\" for col in need_ohe_cols] + already_ohe_cols + [\"scaled_minmax_features\"] + [\"scaled_standard_features\"],\n",
    "        outputCol=\"final_features\"\n",
    "    )\n",
    "\n",
    "pipeline =  Pipeline(stages=indexers + encoders + [imputer] + [minmax_assembler, minmax_scaler, standard_assembler, standard_scaler, final_assembler])\n",
    "\n",
    "pipeline_model = pipeline.fit(df_train_filtered)\n",
    "df_encoded = pipeline_model.transform(df_train_filtered)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ee1140ce-276f-4328-af86-ac60d1ea6eb3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(df_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "af6da075-6f94-4545-b1ee-4d422693ec93",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "input_size = df_encoded.select(\"final_features\").rdd.map(lambda row: row[0].size).distinct().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e2909fd8-7488-490d-9b10-5afe5a0ffb48",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "input_size = input_size[0]\n",
    "print(input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "43a55e3a-2930-4b4b-9e0f-456aca5d0873",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_train_val_data(df, fold):\n",
    "    \"\"\"\n",
    "    Function to filter training and validation sets\n",
    "    \"\"\"\n",
    "    train_data = df.filter((col('split') == 'train') & (col('foldCol') == fold))\n",
    "    val_data = df.filter((col('split') == 'val') & (col('foldCol') == fold))\n",
    "    return train_data, val_data\n",
    "\n",
    "def objective(trial):\n",
    "    expected_length = input_size\n",
    "    hidden_layer_1_size = trial.suggest_int(\"hidden_layer_1_size\", 10, expected_length * 2)\n",
    "    hidden_layer_2_size = trial.suggest_int(\"hidden_layer_2_size\", 10, expected_length)\n",
    "    max_iter = trial.suggest_int(\"max_iter\", 10, 100)\n",
    "    block_size = trial.suggest_int(\"block_size\", 50, 128, log=True)\n",
    "    step_size = trial.suggest_float(\"step_size\", 0.01, 0.1, log=True)\n",
    "    \n",
    "    layers = [expected_length, hidden_layer_1_size, hidden_layer_2_size, 2]\n",
    "    mlp = MultilayerPerceptronClassifier(\n",
    "        featuresCol=\"final_features\",\n",
    "        labelCol=label_col,\n",
    "        maxIter=max_iter,\n",
    "        blockSize=block_size,\n",
    "        stepSize = step_size,\n",
    "        layers=layers\n",
    "    )\n",
    "    \n",
    "    evaluator = BinaryClassificationEvaluator(labelCol=label_col)\n",
    "\n",
    "    fold_metrics = []\n",
    "\n",
    "    # Define number of folds\n",
    "    num_folds = df_encoded.select('foldCol').distinct().count()\n",
    "    print(\"Num folds:\", num_folds)\n",
    "    # Loop through folds\n",
    "    for fold in range(num_folds):\n",
    "        \n",
    "        # Get train and validation data\n",
    "        train_data, val_data = get_train_val_data(df_encoded, fold)\n",
    "\n",
    "        # Train the pipeline and evaluate on both train and validation\n",
    "        try:\n",
    "            print(\"0\")\n",
    "            pipeline_model = mlp.fit(train_data)\n",
    "            print(\"A\")\n",
    "            training_preds = pipeline_model.transform(train_data)\n",
    "            print(\"B\")\n",
    "            val_preds = pipeline_model.transform(val_data)\n",
    "            print(\"C\")\n",
    "            predictions = {\"train\": training_preds, \"val\": val_preds}\n",
    "            print(\"D\")\n",
    "        except Exception as e:\n",
    "            trial.set_user_attr(\"failure_reason\", str(e))\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "        \n",
    "        # Store metrics per key\n",
    "        train_val = []\n",
    "        # Calculate training and validation metrics for this fold\n",
    "        for key, prediction in predictions.items():\n",
    "            tp = prediction.filter((col(label_col) == 1) & (col(\"prediction\") == 1)).count()\n",
    "            fp = prediction.filter((col(label_col) == 0) & (col(\"prediction\") == 1)).count()\n",
    "            fn = prediction.filter((col(label_col) == 1) & (col(\"prediction\") == 0)).count()\n",
    "            tn = prediction.filter((col(label_col) == 0) & (col(\"prediction\") == 0)).count()\n",
    "            print(\"true positives: \", tp)\n",
    "            print(\"false positives: \", fp)\n",
    "            print(\"true negatives: \", tn)\n",
    "            print(\"fasle negatives: \", fn)\n",
    "\n",
    "            # Calculate metrics\n",
    "            precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "            recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "            print(\"precision: \", precision)\n",
    "            print(\"recall: \", recall)\n",
    "            # F-beta score with beta=0.5\n",
    "            beta = 0.5\n",
    "            fbeta = (1 + beta**2) * (precision * recall) / ((beta**2 * precision) + recall) if (precision + recall) > 0 else 0\n",
    "            print(\"fbeta: \", fbeta)\n",
    "            # Store metrics for this fold\n",
    "            p_key = \"precision_\" + key\n",
    "            r_key = \"recall_\" + key\n",
    "            fb_key = \"fbeta_\" + key\n",
    "\n",
    "            train_val.append({\n",
    "                p_key: precision,\n",
    "                r_key: recall,\n",
    "                fb_key: fbeta\n",
    "            })\n",
    "        \n",
    "        fold_weight = {\n",
    "            \"fold\": fold,\n",
    "            \"weight\": fold + 1  # Add weight to the fold metrics\n",
    "        }\n",
    "        \n",
    "        # Merge together and append to fold metrics\n",
    "        fold_metrics.append((fold_weight | train_val[0] | train_val[1]))\n",
    "\n",
    "    # Aggregate metrics across folds with weights\n",
    "    total_weight = sum([m[\"weight\"] for m in fold_metrics])\n",
    "    avg_metrics = {\n",
    "        metric: sum([m[metric] * m[\"weight\"] for m in fold_metrics]) / total_weight\n",
    "        for metric in [\"precision_train\", \"recall_train\", \"fbeta_train\", \"precision_val\", \"recall_val\", \"fbeta_val\"]\n",
    "    }\n",
    "\n",
    "    # Log metrics to Optuna trial\n",
    "    for metric_name, metric_value in avg_metrics.items():\n",
    "        trial.set_user_attr(f\"weighted_average_{metric_name}\", metric_value)\n",
    "\n",
    "    # Report primary metric for pruning\n",
    "    trial.report(avg_metrics[\"fbeta_val\"], step=0)\n",
    "\n",
    "    # Prune trial if not promising\n",
    "    if trial.should_prune():\n",
    "        raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return avg_metrics[\"fbeta_val\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "45b6135d-aca9-4d95-b1a6-5261e18aa942",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##5 YEAR EXPERIMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c1cb8d10-def9-4221-88da-fb9b8811c057",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction=\"maximize\", \n",
    "                            pruner=MedianPruner(n_startup_trials=5, n_warmup_steps=1\n",
    "                                                )\n",
    "                            )\n",
    "study.optimize(objective, \n",
    "               n_trials=10, \n",
    "               n_jobs=-1\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5e3857ef-d2f9-4b50-8d1f-b7342661b816",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "metrics_df = study.trials_dataframe()\n",
    "metrics_df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c28ae125-cc0a-4943-a4f4-3fe1b24e6f55",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(metrics_df.loc[0, 'user_attrs_failure_reason'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1c9b7649-6913-460e-8aae-1af4987fb83c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "optuna.visualization.matplotlib.plot_timeline(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "31bb27bf-4b67-4430-9595-a2a9f043a073",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "optuna.visualization.matplotlib.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b819516e-4450-4205-9826-6752480916f4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "optuna.visualization.matplotlib.plot_contour(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7fb63f07-8301-4175-b767-95b76198c8ce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "optuna.visualization.matplotlib.plot_intermediate_values(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1594d99f-c520-46b1-9eff-e1904034e977",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "optuna.visualization.matplotlib.plot_terminator_improvement(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "213ea0e0-f2b6-4542-b6d9-c694fbe07e6b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "optuna.visualization.plot_parallel_coordinate(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "95527593-7741-4995-b0b1-cf433d1d7676",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ps.DataFrame(metrics_df).to_csv(f\"{team_blob_url}/results/5yr_mlp2\", index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7b000d46-3533-4357-95ed-86ed220c7371",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##RERUN TRAINING MODEL WITH BEST HYPERPARAMETERS TO GET METRICS ACROSS FOLDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b0039d1f-e6cc-40f2-b7de-89d3c9f48788",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_train_val_data(df, fold):\n",
    "    \"\"\"\n",
    "    Function to filter training and validation sets\n",
    "    \"\"\"\n",
    "    train_data = df.filter((col('split') == 'train') & (col('foldCol') == fold))\n",
    "    val_data = df.filter((col('split') == 'val') & (col('foldCol') == fold))\n",
    "    return train_data, val_data\n",
    "\n",
    "def objective(trial):\n",
    "    input_size = 85\n",
    "    mlp = MultilayerPerceptronClassifier(\n",
    "    featuresCol=\"final_features\",\n",
    "    labelCol=label_col,\n",
    "    maxIter=82,#best_params[\"max_iter\"],#89,\n",
    "    blockSize=128,#best_params[\"block_size\"],#24,\n",
    "    stepSize = 0.011909,#best_params[\"step_size\"],#0.012987,\n",
    "    layers=[input_size, \n",
    "            14,#best_params[\"hidden_layer_1_size\"], \n",
    "            15,#best_params[\"hidden_layer_2_size\"], \n",
    "            2]\n",
    ")\n",
    "    fold_metrics = {\"train\": [], \"val\": []}\n",
    "    num_folds = df_encoded.select('foldCol').distinct().count()\n",
    "    fold_weights = range(1, num_folds + 1)\n",
    "\n",
    "    for fold in range(num_folds):\n",
    "        train_data, val_data = get_train_val_data(df_encoded, fold)\n",
    "        print(f\"Fold {fold} of {num_folds}\")\n",
    "        pipeline_model = mlp.fit(train_data)\n",
    "       \n",
    "        # Evaluate on train and validation data\n",
    "        for split_name, data in [(\"train\", train_data), (\"val\", val_data)]:\n",
    "            predictions = pipeline_model.transform(data)\n",
    "            #auc = evaluator.evaluate(predictions)\n",
    "            print('a')\n",
    "            # Compute metrics\n",
    "            tp = predictions.filter((col(label_col) == 1) & (col(\"prediction\") == 1)).count()\n",
    "            fp = predictions.filter((col(label_col) == 0) & (col(\"prediction\") == 1)).count()\n",
    "            fn = predictions.filter((col(label_col) == 1) & (col(\"prediction\") == 0)).count()\n",
    "            tn = predictions.filter((col(label_col) == 0) & (col(\"prediction\") == 0)).count()\n",
    "\n",
    "            precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "            recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "            accuracy = (tp + tn) / (tp + tn + fp + fn) if (tp + tn + fp + fn) > 0 else 0\n",
    "\n",
    "            f1_micro = accuracy\n",
    "            f1_macro = (precision + recall) / 2 if (precision + recall) > 0 else 0\n",
    "            f1_weighted = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "            beta = 0.5\n",
    "            fbeta = (1 + beta**2) * (precision * recall) / ((beta**2 * precision) + recall) if (precision + recall) > 0 else 0\n",
    "            print('b')\n",
    "            # Store fold metrics\n",
    "            fold_metrics[split_name].append({\n",
    "                \"fold\": fold,\n",
    "                #\"auc\": auc,\n",
    "                \"precision\": precision,\n",
    "                \"recall\": recall,\n",
    "                \"accuracy\": accuracy,\n",
    "                \"f1_micro\": f1_micro,\n",
    "                \"f1_macro\": f1_macro,\n",
    "                \"f1_weighted\": f1_weighted,\n",
    "                \"fbeta\": fbeta,\n",
    "                \"weight\": fold_weights[fold]\n",
    "            })\n",
    "\n",
    "            # Log fold-specific metrics\n",
    "            for metric_name, metric_value in {\n",
    "                \"precision\": precision, \"recall\": recall,\n",
    "                \"accuracy\": accuracy, \"f1_micro\": f1_micro, \"f1_macro\": f1_macro,\n",
    "                \"f1_weighted\": f1_weighted, \"fbeta\": fbeta\n",
    "            }.items():\n",
    "                trial.set_user_attr(f\"{split_name}_fold_{fold}_{metric_name}\", metric_value)\n",
    "\n",
    "    # Aggregate metrics across folds for train and val separately\n",
    "    metrics_per_split = {}\n",
    "    for split_name in [\"train\", \"val\"]:\n",
    "        total_weight = sum(m[\"weight\"] for m in fold_metrics[split_name])\n",
    "\n",
    "        metrics_per_split[split_name] = {\n",
    "            metric: sum(m[metric] * m[\"weight\"] for m in fold_metrics[split_name]) / total_weight\n",
    "            for metric in [\"precision\", \"recall\", \"accuracy\", \"f1_micro\", \"f1_macro\", \"f1_weighted\", \"fbeta\"]\n",
    "        }\n",
    "\n",
    "    # Log aggregated metrics\n",
    "    for split_name, metrics in metrics_per_split.items():\n",
    "        for metric_name, metric_value in metrics.items():\n",
    "            trial.set_user_attr(f\"{split_name}_weighted_average_{metric_name}\", metric_value)\n",
    "\n",
    "    # Store per-fold metrics for later analysis\n",
    "    trial.set_user_attr(\"fold_metrics\", fold_metrics)\n",
    "\n",
    "    trial.report(metrics_per_split[\"val\"][\"fbeta\"], step=0)\n",
    "\n",
    "    if trial.should_prune():\n",
    "        raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    print('Fold metrics stored in trial user attributes')\n",
    "    print('val fbeta:', metrics_per_split[\"val\"][\"fbeta\"])\n",
    "    return metrics_per_split[\"val\"][\"fbeta\"]\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\", \n",
    "                            pruner=MedianPruner(n_startup_trials=5, n_warmup_steps=1\n",
    "                                                )\n",
    "                            )\n",
    "study.optimize(objective, \n",
    "               n_trials=1, \n",
    "               n_jobs=-1\n",
    "               )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5be3767a-b83c-4096-a9ca-6c39652cbaca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def study_to_dataframe(study):\n",
    "    records = []\n",
    "    for trial in study.trials:\n",
    "        # Extract general metrics\n",
    "        record = {\n",
    "            \"trial_number\": trial.number,\n",
    "            \"state\": trial.state.name,  # Use human-readable state\n",
    "            \"train_accuracy\": trial.user_attrs.get(\"train_weighted_average_accuracy\"),\n",
    "            #\"train_auc\": trial.user_attrs.get(\"train_weighted_average_auc\"),\n",
    "            \"train_f1_macro\": trial.user_attrs.get(\"train_weighted_average_f1_macro\"),\n",
    "            \"train_f1_micro\": trial.user_attrs.get(\"train_weighted_average_f1_micro\"),\n",
    "            \"train_f1_weighted\": trial.user_attrs.get(\"train_weighted_average_f1_weighted\"),\n",
    "            \"train_fbeta\": trial.user_attrs.get(\"train_weighted_average_fbeta\"),\n",
    "            \"train_precision\": trial.user_attrs.get(\"train_weighted_average_precision\"),\n",
    "            \"train_recall\": trial.user_attrs.get(\"train_weighted_average_recall\"),\n",
    "            \"val_accuracy\": trial.user_attrs.get(\"val_weighted_average_accuracy\"),\n",
    "            #\"val_auc\": trial.user_attrs.get(\"val_weighted_average_auc\"),\n",
    "            \"val_f1_macro\": trial.user_attrs.get(\"val_weighted_average_f1_macro\"),\n",
    "            \"val_f1_micro\": trial.user_attrs.get(\"val_weighted_average_f1_micro\"),\n",
    "            \"val_f1_weighted\": trial.user_attrs.get(\"val_weighted_average_f1_weighted\"),\n",
    "            \"val_fbeta\": trial.user_attrs.get(\"val_weighted_average_fbeta\"),\n",
    "            \"val_precision\": trial.user_attrs.get(\"val_weighted_average_precision\"),\n",
    "            \"val_recall\": trial.user_attrs.get(\"val_weighted_average_recall\"),\n",
    "            **trial.params,  # Add hyperparameters as columns\n",
    "        }\n",
    "\n",
    "        # Add fold-specific metrics\n",
    "        for key, value in trial.user_attrs.items():\n",
    "            if \"fold_\" in key:  # Capture fold-specific metrics\n",
    "                record[key] = value\n",
    "\n",
    "        records.append(record)\n",
    "\n",
    "    # Create a DataFrame with pyspark.pandas\n",
    "    df_metrics = ps.DataFrame(records)\n",
    "    return df_metrics\n",
    "\n",
    "\n",
    "# Convert study results to a DataFrame\n",
    "df_metrics = study_to_dataframe(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0b4d2e04-a429-46a6-8132-496403f92ab4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(df_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6c9cc567-0994-4825-bdc6-7770eb4acb05",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##5 YEAR TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4b2ac047-4e70-4d88-bba1-32370f6d352a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def calculate_metrics(prediction, beta=0.5):\n",
    "    tp = prediction.filter((col(label_col) == 1) & (col(\"prediction\") == 1)).count()\n",
    "    fp = prediction.filter((col(label_col) == 0) & (col(\"prediction\") == 1)).count()\n",
    "    fn = prediction.filter((col(label_col) == 1) & (col(\"prediction\") == 0)).count()\n",
    "    tn = prediction.filter((col(label_col) == 0) & (col(\"prediction\") == 0)).count()\n",
    "\n",
    "    # Calculate metrics\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "\n",
    "    # F-beta score with beta=0.5\n",
    "    beta = 0.5\n",
    "    fbeta = (1 + beta**2) * (precision * recall) / ((beta**2 * precision) + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "    return fbeta, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "88e44997-f340-4cdf-acd6-fdf0b614be64",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "best_params = study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4aaac736-2786-40ed-906b-039819a1d323",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def blind_test(train, test):\n",
    "    input_size = 85\n",
    "    mlp = MultilayerPerceptronClassifier(\n",
    "        featuresCol=\"final_features\",\n",
    "        labelCol=label_col,\n",
    "        maxIter=best_params[\"max_iter\"],\n",
    "        blockSize=128,\n",
    "        stepSize = best_params[\"step_size\"],\n",
    "        layers=[input_size, \n",
    "                best_params[\"hidden_layer_1_size\"], \n",
    "                best_params[\"hidden_layer_2_size\"], \n",
    "                2]\n",
    "    )\n",
    "    #print(\"Max Iter: \", best_params[\"max_iter\"])\n",
    "    #print(\"Step Size: \", best_params[\"step_size\"])\n",
    "    #print(\"Hidden Layer 1 Size: \", best_params[\"hidden_layer_1_size\"])\n",
    "    #print(\"Hidden Layer 2 Size: \", best_params[\"hidden_layer_2_size\"])\n",
    "    indexers = [StringIndexer(inputCol=col, outputCol=f\"{col}_index\", handleInvalid=\"keep\") for col in need_ohe_cols]\n",
    "    encoders = [OneHotEncoder(inputCol=f\"{col}_index\", outputCol=f\"{col}_ohe\", dropLast=False) for col in need_ohe_cols]\n",
    "    imputer = Imputer(strategy=\"mean\", inputCols=numerical_cols, outputCols=[f\"{col}_imputed\" for col in numerical_cols])\n",
    "\n",
    "    minmax_assembler = VectorAssembler(inputCols=[f\"{col}_imputed\" for col in min_max_cols], outputCol=\"minmax_features\")\n",
    "    minmax_scaler = MinMaxScaler(inputCol=\"minmax_features\", outputCol=\"scaled_minmax_features\")\n",
    "\n",
    "    # Assemble input columns for StandardScaler\n",
    "    standard_assembler = VectorAssembler(inputCols=[f\"{col}_imputed\" for col in standard_scalar_cols], outputCol=\"standard_features\")\n",
    "    standard_scaler = StandardScaler(inputCol=\"standard_features\", outputCol=\"scaled_standard_features\", withMean=True, withStd=True)\n",
    "\n",
    "    final_assembler = VectorAssembler(\n",
    "            inputCols=[f\"{col}_ohe\" for col in need_ohe_cols] + already_ohe_cols + [\"scaled_minmax_features\"] + [\"scaled_standard_features\"],\n",
    "            outputCol=\"final_features\"\n",
    "        )\n",
    "    \n",
    "    pipeline =  Pipeline(stages=indexers + encoders + [imputer] + [minmax_assembler, minmax_scaler, standard_assembler, standard_scaler, final_assembler, mlp])\n",
    "\n",
    "    mlp_model = pipeline.fit(train)\n",
    "    training_preds = mlp_model.transform(train)\n",
    "    test_preds = mlp_model.transform(test)\n",
    "\n",
    "    predictions = {\"train\": training_preds, \"test\": test_preds}\n",
    "\n",
    "    # Store metrics per key\n",
    "    train_test = []\n",
    "    # Calculate training and validation metrics\n",
    "    print(\"A\")\n",
    "    for key, prediction in predictions.items():\n",
    "        fbeta, precision, recall = calculate_metrics(prediction)\n",
    "\n",
    "        # Store metrics for this fold\n",
    "        p_key = \"precision_\" + key\n",
    "        r_key = \"recall_\" + key\n",
    "        fb_key = \"fbeta_\" + key\n",
    "\n",
    "        train_test.append({\n",
    "            p_key: precision,\n",
    "            r_key: recall,\n",
    "            fb_key: fbeta\n",
    "        })\n",
    "    \n",
    "    metrics = train_test[0] | train_test[1]\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "76662a2e-28fc-4433-8300-475d3a93f943",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "train_5yr = df_train_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8fd73f07-f6d7-4245-a669-0220503d7b86",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(train_5yr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e88d8240-ba08-4ab8-8b9a-d7c12a7573e9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "test_5yr = spark.read.parquet(f'{team_blob_url}/data/5yr_test.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "90748340-4dce-40c9-a004-e563f298cf4b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(test_5yr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ec24e434-7266-4f36-a0a5-fcdd02bf148d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "test_5yr = test_5yr.filter(test_5yr.DEP_DEL15.isNotNull())\n",
    "test_5yr = test_5yr.withColumn(\"specWeather\", F.when(col(\"specWeather\") > 0, 1).otherwise(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "da8817a6-867a-49c6-83a2-e685f05bc00a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "test_5yr = test_5yr.drop(*['ORIGIN', 'DEST','FL_DATE', 'CANCELLED', 'YEAR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5b81a7c6-849f-43c4-a254-48751eccb13e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "results = blind_test(train_5yr, test_5yr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8c5532f8-9200-4c25-81fc-9e8c7d7d1310",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b7b00d5c-093c-42bf-8218-8c8c9ec74d1c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d8747556-56d8-43fe-a1f2-b005721432ca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "input_size = 85\n",
    "mlp = MultilayerPerceptronClassifier(\n",
    "    featuresCol=\"final_features\",\n",
    "    labelCol=label_col,\n",
    "    maxIter=best_params[\"max_iter\"],\n",
    "    blockSize=128,\n",
    "    stepSize = best_params[\"step_size\"],\n",
    "    layers=[input_size, \n",
    "            best_params[\"hidden_layer_1_size\"], \n",
    "            best_params[\"hidden_layer_2_size\"], \n",
    "            2]\n",
    ")\n",
    "#print(\"Max Iter: \", best_params[\"max_iter\"])\n",
    "#print(\"Step Size: \", best_params[\"step_size\"])\n",
    "#print(\"Hidden Layer 1 Size: \", best_params[\"hidden_layer_1_size\"])\n",
    "#print(\"Hidden Layer 2 Size: \", best_params[\"hidden_layer_2_size\"])\n",
    "indexers = [StringIndexer(inputCol=col, outputCol=f\"{col}_index\", handleInvalid=\"keep\") for col in need_ohe_cols]\n",
    "encoders = [OneHotEncoder(inputCol=f\"{col}_index\", outputCol=f\"{col}_ohe\", dropLast=False) for col in need_ohe_cols]\n",
    "imputer = Imputer(strategy=\"mean\", inputCols=numerical_cols, outputCols=[f\"{col}_imputed\" for col in numerical_cols])\n",
    "\n",
    "minmax_assembler = VectorAssembler(inputCols=[f\"{col}_imputed\" for col in min_max_cols], outputCol=\"minmax_features\")\n",
    "minmax_scaler = MinMaxScaler(inputCol=\"minmax_features\", outputCol=\"scaled_minmax_features\")\n",
    "\n",
    "# Assemble input columns for StandardScaler\n",
    "standard_assembler = VectorAssembler(inputCols=[f\"{col}_imputed\" for col in standard_scalar_cols], outputCol=\"standard_features\")\n",
    "standard_scaler = StandardScaler(inputCol=\"standard_features\", outputCol=\"scaled_standard_features\", withMean=True, withStd=True)\n",
    "\n",
    "final_assembler = VectorAssembler(\n",
    "        inputCols=[f\"{col}_ohe\" for col in need_ohe_cols] + already_ohe_cols + [\"scaled_minmax_features\"] + [\"scaled_standard_features\"],\n",
    "        outputCol=\"final_features\"\n",
    "    )\n",
    "\n",
    "pipeline =  Pipeline(stages=indexers + encoders + [imputer] + [minmax_assembler, minmax_scaler, standard_assembler, standard_scaler, final_assembler, mlp])\n",
    "\n",
    "mlp_model = pipeline.fit(train_5yr.filter(col('split') == 'train'))\n",
    "mlp_model = mlp_model.stages[-1]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ddb583a5-4f04-4412-a62c-de64af021299",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "coefficients = mlp_model.weights.toArray()\n",
    "\n",
    "\n",
    "feature_names = categorical_cols + numerical_cols \n",
    "feature_coeffs = dict(zip(feature_names, coefficients))\n",
    "\n",
    "# Calculate class-specific contributions\n",
    "class_1_contributions = coefficients  # Coefficients directly favor Class 1\n",
    "class_0_contributions = -coefficients  # Negative coefficients favor Class 0\n",
    "\n",
    "# Sort coefficients for Class 1\n",
    "sorted_class_1 = sorted(zip(feature_names, class_1_contributions), key=lambda x: abs(x[1]), reverse=True)\n",
    "sorted_names_1, sorted_values_1 = zip(*sorted_class_1)\n",
    "\n",
    "# Sort coefficients for Class 0\n",
    "sorted_class_0 = sorted(zip(feature_names, class_0_contributions), key=lambda x: abs(x[1]), reverse=True)\n",
    "sorted_names_0, sorted_values_0 = zip(*sorted_class_0)\n",
    "\n",
    "# Define styling for both plots\n",
    "bar_color = \"#4DD0E1\"\n",
    "background_color = \"#212121\"\n",
    "label_color = \"white\"\n",
    "\n",
    "# Plot Coefficients for Class 1\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(sorted_names_1, sorted_values_1, color=bar_color)\n",
    "plt.xlabel(\"Coefficient Value for Class 1\", color=label_color)\n",
    "plt.ylabel(\"Features\", color=label_color)\n",
    "plt.title(\"MLP 2 Hidden Layers Coefficients (Class 1)\", color=label_color)\n",
    "plt.gca().invert_yaxis()\n",
    "plt.gca().set_facecolor(background_color)\n",
    "plt.gcf().set_facecolor(background_color)\n",
    "plt.tick_params(colors=label_color)\n",
    "plt.grid(False)\n",
    "plt.show()\n",
    "\n",
    "# Plot Coefficients for Class 0\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(sorted_names_0, sorted_values_0, color=bar_color)\n",
    "plt.xlabel(\"Coefficient Value for Class 0\", color=label_color)\n",
    "plt.ylabel(\"Features\", color=label_color)\n",
    "plt.title(\"MLP 2 Hidden Layers Coefficients (Class 0)\", color=label_color)\n",
    "plt.gca().invert_yaxis()\n",
    "plt.gca().set_facecolor(background_color)\n",
    "plt.gcf().set_facecolor(background_color)\n",
    "plt.tick_params(colors=label_color)\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "aaebc1d5-07d3-4d0f-995e-74d9fd721492",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##1 YEAR EXPERIMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "745fc01e-1f6d-4a14-892e-d7fcb3032973",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction=\"maximize\", \n",
    "                            pruner=MedianPruner(n_startup_trials=5, n_warmup_steps=1\n",
    "                                                )\n",
    "                            )\n",
    "study.optimize(objective, \n",
    "               n_trials=5, \n",
    "               n_jobs=-1\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7a567c08-1db4-447a-85c5-4c8f9c979d63",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "metrics_df = study.trials_dataframe()\n",
    "metrics_df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "11a70746-d9c1-4c57-93e5-7579e27289b7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_train_val_data(df, fold):\n",
    "    \"\"\"\n",
    "    Function to filter training and validation sets\n",
    "    \"\"\"\n",
    "    train_data = df.filter((col('split') == 'train') & (col('foldCol') == fold))\n",
    "    val_data = df.filter((col('split') == 'val') & (col('foldCol') == fold))\n",
    "    return train_data, val_data\n",
    "\n",
    "def objective(trial):\n",
    "    expected_length = 125\n",
    "    hidden_layer_size = trial.suggest_int(\"hidden_layer_size\", 10, expected_length * 2)\n",
    "    max_iter = trial.suggest_int(\"max_iter\", 10, 100)\n",
    "    block_size = trial.suggest_int(\"block_size\", 50, 120, log=True)\n",
    "    step_size = trial.suggest_float(\"step_size\", 0.01, 0.1, log=True)\n",
    "    imputation_strategy = trial.suggest_categorical(\"imputation_strategy\", [\"mean\", \"median\"])\n",
    "\n",
    "    indexers = [StringIndexer(inputCol=col, outputCol=f\"{col}_index\", handleInvalid=\"keep\") for col in need_ohe_cols]\n",
    "    encoders = [OneHotEncoder(inputCol=f\"{col}_index\", outputCol=f\"{col}_ohe\", dropLast=False) for col in need_ohe_cols]\n",
    "    imputer = Imputer(strategy=imputation_strategy, inputCols=numerical_cols, outputCols=[f\"{col}_imputed\" for col in numerical_cols])\n",
    "\n",
    "    minmax_assembler = VectorAssembler(inputCols=min_max_cols, outputCol=\"minmax_features\")\n",
    "    minmax_scaler = MinMaxScaler(inputCol=\"minmax_features\", outputCol=\"scaled_minmax_features\")\n",
    "\n",
    "    # Assemble input columns for StandardScaler\n",
    "    standard_assembler = VectorAssembler(inputCols=standard_scalar_cols, outputCol=\"standard_features\")\n",
    "    standard_scaler = StandardScaler(inputCol=\"standard_features\", outputCol=\"scaled_standard_features\", withMean=True, withStd=True)\n",
    "\n",
    "    final_assembler = VectorAssembler(\n",
    "            inputCols=[f\"{col}_ohe\" for col in need_ohe_cols] + already_ohe_cols + [\"scaled_minmax_features\"] + [\"scaled_standard_features\"],\n",
    "            outputCol=\"final_features\"\n",
    "        )    \n",
    "\n",
    "    #temp_pipeline = Pipeline(stages=indexers + encoders + [imputer] + [minmax_assembler, minmax_scaler, standard_assembler, standard_scaler, final_assembler])\n",
    "    #temp_model = temp_pipeline.fit(test_df)\n",
    "    #df_temp = temp_model.transform(test_df)\n",
    "    #expected_length = df_temp.select(\"final_features\").rdd.map(lambda row: row[0].size).distinct().collect()\n",
    "    #display(df_temp)\n",
    "    # Determine the sparse vector length\n",
    "    #first_row = df_temp.select(\"final_features\").first()\n",
    "    #expected_length = first_row[\"final_features\"].size\n",
    "    #print(expected_length)\n",
    "\n",
    "    #hidden_layer_size = trial.suggest_int(\"hidden_layer_size\", 10, expected_length)\n",
    "    layers = [expected_length, hidden_layer_size, 2]\n",
    "    mlp = MultilayerPerceptronClassifier(\n",
    "        featuresCol=\"final_features\",\n",
    "        labelCol=label_col,\n",
    "        maxIter=max_iter,\n",
    "        blockSize=block_size,\n",
    "        stepSize = step_size,\n",
    "        layers=layers\n",
    "    )\n",
    "    pipeline =  Pipeline(stages=indexers + encoders + [imputer] + [minmax_assembler, minmax_scaler, standard_assembler, standard_scaler, final_assembler, mlp])\n",
    "    \n",
    "    evaluator = BinaryClassificationEvaluator(labelCol=label_col)\n",
    "\n",
    "    fold_metrics = []\n",
    "\n",
    "    # Define number of folds\n",
    "    num_folds = test_df.select('foldCol').distinct().count()\n",
    "    print(\"Num folds:\", num_folds)\n",
    "    # Loop through folds\n",
    "    for fold in range(num_folds):\n",
    "        \n",
    "        # Get train and validation data\n",
    "        train_data, val_data = get_train_val_data(test_df, fold)\n",
    "\n",
    "        # Train the pipeline and evaluate on both train and validation\n",
    "        try:\n",
    "            print(\"0\")\n",
    "            pipeline_model = pipeline.fit(train_data)\n",
    "            print(\"A\")\n",
    "            training_preds = pipeline_model.transform(train_data)\n",
    "            print(\"B\")\n",
    "            val_preds = pipeline_model.transform(val_data)\n",
    "            print(\"C\")\n",
    "            predictions = {\"train\": training_preds, \"val\": val_preds}\n",
    "            print(\"D\")\n",
    "        except Exception as e:\n",
    "            trial.set_user_attr(\"failure_reason\", str(e))\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "        \n",
    "        # Store metrics per key\n",
    "        train_val = []\n",
    "        # Calculate training and validation metrics for this fold\n",
    "        for key, prediction in predictions.items():\n",
    "            tp = prediction.filter((col(label_col) == 1) & (col(\"prediction\") == 1)).count()\n",
    "            fp = prediction.filter((col(label_col) == 0) & (col(\"prediction\") == 1)).count()\n",
    "            fn = prediction.filter((col(label_col) == 1) & (col(\"prediction\") == 0)).count()\n",
    "            tn = prediction.filter((col(label_col) == 0) & (col(\"prediction\") == 0)).count()\n",
    "\n",
    "            # Calculate metrics\n",
    "            precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "            recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "\n",
    "            # F-beta score with beta=0.5\n",
    "            beta = 0.5\n",
    "            fbeta = (1 + beta**2) * (precision * recall) / ((beta**2 * precision) + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "            # Store metrics for this fold\n",
    "            p_key = \"precision_\" + key\n",
    "            r_key = \"recall_\" + key\n",
    "            fb_key = \"fbeta_\" + key\n",
    "\n",
    "            train_val.append({\n",
    "                p_key: precision,\n",
    "                r_key: recall,\n",
    "                fb_key: fbeta\n",
    "            })\n",
    "        \n",
    "        fold_weight = {\n",
    "            \"fold\": fold,\n",
    "            \"weight\": fold + 1  # Add weight to the fold metrics\n",
    "        }\n",
    "        \n",
    "        # Merge together and append to fold metrics\n",
    "        fold_metrics.append((fold_weight | train_val[0] | train_val[1]))\n",
    "\n",
    "    # Aggregate metrics across folds with weights\n",
    "    total_weight = sum([m[\"weight\"] for m in fold_metrics])\n",
    "    avg_metrics = {\n",
    "        metric: sum([m[metric] * m[\"weight\"] for m in fold_metrics]) / total_weight\n",
    "        for metric in [\"precision_train\", \"recall_train\", \"fbeta_train\", \"precision_val\", \"recall_val\", \"fbeta_val\"]\n",
    "    }\n",
    "\n",
    "    # Log metrics to Optuna trial\n",
    "    for metric_name, metric_value in avg_metrics.items():\n",
    "        trial.set_user_attr(f\"weighted_average_{metric_name}\", metric_value)\n",
    "\n",
    "    # Report primary metric for pruning\n",
    "    trial.report(avg_metrics[\"fbeta_val\"], step=0)\n",
    "\n",
    "    # Prune trial if not promising\n",
    "    if trial.should_prune():\n",
    "        raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return avg_metrics[\"fbeta_val\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "95a5480e-0df7-4070-8fe2-c49390158dfe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(metrics_df.loc[0, 'user_attrs_failure_reason'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "cb5f5ce1-3d0f-4045-b460-7904b3aeef39",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    hidden_layer_size = trial.suggest_int(\"hidden_layer_size\", 10, 125)\n",
    "    max_iter = trial.suggest_int(\"max_iter\", 10, 100)\n",
    "    block_size = trial.suggest_int(\"block_size\", 64, 256, log=True)\n",
    "    step_size = trial.suggest_float(\"step_size\", 0.01, 0.1, log=True)\n",
    "    imputation_strategy = trial.suggest_categorical(\"imputation_strategy\", [\"mean\", \"median\"])\n",
    "\n",
    "    indexers = [StringIndexer(inputCol=col, outputCol=f\"{col}_index\") for col in categorical_cols]\n",
    "    encoders = [OneHotEncoder(inputCol=f\"{col}_index\", outputCol=f\"{col}_ohe\", dropLast=False) for col in categorical_cols]\n",
    "    imputer = Imputer(strategy=imputation_strategy, inputCols=numerical_cols, outputCols=[f\"{col}_imputed\" for col in numerical_cols])\n",
    "\n",
    "    minmax_assembler = VectorAssembler(inputCols=min_max_cols, outputCol=\"minmax_features\")\n",
    "    minmax_scaler = MinMaxScaler(inputCol=\"minmax_features\", outputCol=\"scaled_minmax_features\")\n",
    "\n",
    "    # Assemble input columns for StandardScaler\n",
    "    standard_assembler = VectorAssembler(inputCols=standard_scalar_cols + ohe_cols, outputCol=\"standard_features\")\n",
    "    standard_scaler = StandardScaler(inputCol=\"standard_features\", outputCol=\"scaled_standard_features\", withMean=True, withStd=True)\n",
    "\n",
    "    final_assembler = VectorAssembler(\n",
    "            inputCols=[f\"{col}_ohe\" for col in categorical_cols] + [\"scaled_minmax_features\"] + [\"scaled_standard_features\"],\n",
    "            outputCol=\"final_features\"\n",
    "        )    \n",
    "    temp_pipeline = Pipeline(stages=indexers + encoders + [imputer] + [minmax_assembler, minmax_scaler, standard_assembler, standard_scaler, final_assembler])\n",
    "    temp_model = temp_pipeline.fit(df_train_filtered)\n",
    "    df_temp = temp_model.transform(df_train_filtered)\n",
    "\n",
    "    # Determine the sparse vector length\n",
    "    first_row = df_temp.select(\"final_features\").first()\n",
    "    expected_length = first_row[\"final_features\"].size\n",
    "    print(expected_length)\n",
    "    layers = [expected_length, hidden_layer_size, 2]\n",
    "    mlp = MultilayerPerceptronClassifier(\n",
    "        featuresCol=\"final_features\",\n",
    "        labelCol=label_col,\n",
    "        maxIter=max_iter,\n",
    "        blockSize=block_size,\n",
    "        stepSize = step_size,\n",
    "        layers=layers\n",
    "    )\n",
    "    pipeline =  Pipeline(stages=indexers + encoders + [imputer] + [minmax_assembler, minmax_scaler, standard_assembler, standard_scaler, final_assembler, mlp])\n",
    "\n",
    "    evaluator = BinaryClassificationEvaluator(labelCol=label_col)\n",
    "    paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(mlp.maxIter, [10, 50, 100]) \\\n",
    "    .addGrid(mlp.blockSize, [64, 128, 256]) \\\n",
    "    .addGrid(mlp.stepSize, [0.01, 0.05, 0.1]) \\\n",
    "    .addGrid(mlp.layers, [[expected_length, expected_length / 4, 2], [expected_length, expected_length / 2, 2], [expected_length, expected_length, 2]]) \\\n",
    "    .build()\n",
    "\n",
    "    crossval = CrossValidator(\n",
    "        estimator=pipeline,\n",
    "        estimatorParamMaps=paramGrid,\n",
    "        evaluator=evaluator,\n",
    "        numFolds=5,\n",
    "        foldCol=\"foldCol\",\n",
    "        parallelism=1\n",
    "    )\n",
    "\n",
    "    cv_model = crossval.fit(df_train_filtered)\n",
    "\n",
    "    # Generate predictions\n",
    "    predictions = cv_model.transform(df_train_filtered)\n",
    "\n",
    "    # Initialize metrics dictionary\n",
    "    metrics = {}\n",
    "\n",
    "    # Binary classification metrics\n",
    "    metrics[\"auc_roc\"] = evaluator.evaluate(predictions)\n",
    "\n",
    "    # Custom F-beta calculation\n",
    "    tp = predictions.filter((col(label_col) == 1) & (col(\"prediction\") == 1)).count()\n",
    "    fp = predictions.filter((col(label_col) == 0) & (col(\"prediction\") == 1)).count()\n",
    "    fn = predictions.filter((col(label_col) == 1) & (col(\"prediction\") == 0)).count()\n",
    "    tn = predictions.filter((col(label_col) == 0) & (col(\"prediction\") == 0)).count()\n",
    "\n",
    "    # Calculate metrics\n",
    "    metrics[\"accuracy\"] = (tp + tn) / (tp + tn + fp + fn) if (tp + tn + fp + fn) > 0 else 0\n",
    "    metrics[\"precision\"] = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    metrics[\"recall\"] = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "\n",
    "    # F1-score calculations\n",
    "    metrics[\"f1_micro\"] = metrics[\"accuracy\"]  # Equivalent for micro-averaging in binary classification\n",
    "    metrics[\"f1_macro\"] = (metrics[\"precision\"] + metrics[\"recall\"]) / 2 if (metrics[\"precision\"] + metrics[\"recall\"]) > 0 else 0\n",
    "    metrics[\"f1_weighted\"] = (2 * metrics[\"precision\"] * metrics[\"recall\"]) / (metrics[\"precision\"] + metrics[\"recall\"]) if (metrics[\"precision\"] + metrics[\"recall\"]) > 0 else 0\n",
    "\n",
    "    # F-beta score with beta=0.5\n",
    "    beta = 0.5\n",
    "    if metrics[\"precision\"] + metrics[\"recall\"] == 0:\n",
    "        metrics[\"fbeta\"] = 0\n",
    "    else:\n",
    "        metrics[\"fbeta\"] = (1 + beta**2) * (metrics[\"precision\"] * metrics[\"recall\"]) / ((beta**2 * metrics[\"precision\"]) + metrics[\"recall\"])\n",
    "\n",
    "    # Log metrics to Optuna trial\n",
    "    for metric_name, metric_value in metrics.items():\n",
    "        trial.set_user_attr(metric_name, metric_value)\n",
    "\n",
    "    # Report primary metric for pruning\n",
    "    trial.report(metrics[\"fbeta\"], step=0)\n",
    "\n",
    "    # Prune trial if not promising\n",
    "    if trial.should_prune():\n",
    "        raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return metrics[\"fbeta\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3a17a6e4-46ed-4ae4-8dfc-dacfd123736e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert Optuna study to a DataFrame\n",
    "def study_to_dataframe(study):\n",
    "    records = []\n",
    "    for trial in study.trials:\n",
    "        record = {\n",
    "            \"trial_number\": trial.number,\n",
    "            \"state\": trial.state,\n",
    "            \"accuracy\": trial.user_attrs.get(\"accuracy\"),\n",
    "            \"precision\": trial.user_attrs.get(\"precision\"),\n",
    "            \"recall\": trial.user_attrs.get(\"recall\"),\n",
    "            \"f1_micro\": trial.user_attrs.get(\"f1_micro\"),\n",
    "            \"f1_macro\": trial.user_attrs.get(\"f1_macro\"),\n",
    "            \"f1_weighted\": trial.user_attrs.get(\"f1_weighted\"),\n",
    "            \"auc_roc\": trial.user_attrs.get(\"auc_roc\"),\n",
    "            **trial.params,\n",
    "        }\n",
    "        records.append(record)\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "# Create the DataFrame\n",
    "df_metrics = study_to_dataframe(study)\n",
    "df_metrics.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d35cfe57-7d47-4f91-9287-8c8ebe9c6b2e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "optuna.visualization.matplotlib.plot_timeline(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3ecda525-dd06-49fa-b334-b3421b187339",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "optuna.visualization.matplotlib.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bb16972f-1417-4dd0-82b9-88b4e156aefb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "optuna.visualization.matplotlib.plot_contour(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6b67729e-fcb8-4b84-8d7e-e463db3ac193",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "optuna.visualization.matplotlib.plot_intermediate_values(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "16dc75c3-331c-4362-82e0-321b203e5ded",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "optuna.visualization.matplotlib.plot_terminator_improvement(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ddc7140f-7f98-4e88-a0a8-5bfb8e2a39e8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "optuna.visualization.plot_parallel_coordinate(study)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "(Clone) model_mlp_2L",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}